install.packages("igraph")
library(igraph)
install.packages("shiny")
shiny::runApp('Blog/aws/201511wikisne/wikisne')
install.packages("shinyBS")
shiny::runApp('Blog/aws/201511wikisne/wikisne')
install.packages("wordcloud")
shiny::runApp('Blog/aws/201511wikisne/wikisne')
install.packages("tm")
6.27/9
library(ElemStatLearn)
summary(zip.train)
zip.sym <- zip.train[,1]
install.packages("ElemStatLearn")
library(ElemStatLearn)
summary(zip.train)
zip.sym <- zip.train[,1]
zip.sym
zip.test
library(randomForest)
install.packages("randomForest")
library(randomForest)
zip.rf = randomForest(
zip.class ~ . - V1,
data=zip,
xtest=zip.test[,2:257],
ytest=factor(zip.test.class),
ntree=500,
type="class"
)
zip.rf = randomForest(
V1 ~ . - V1,
data=zip.train,
xtest=zip.test[,2:257],
ytest=factor(zip.test[,1]),
ntree=500,
type="class"
)
?randomForest
zip.rf = randomForest(
V1 ~ . - V1,
data=zip.train,
#xtest=zip.test[,2:257],
#ytest=factor(zip.test[,1]),
ntree=500,
type="class"
)
print(zip.rf)
zip.rf = randomForest(
x ~ zip.train[,2:257],
y ~ factor(zip.train[,1]),
xtest=zip.test[,2:257],
ytest=factor(zip.test[,1]),
ntree=500,
type="class"
)
zip.rf = randomForest(
x=zip.train[,2:257],
y=factor(zip.train[,1]),
xtest=zip.test[,2:257],
ytest=factor(zip.test[,1]),
ntree=500,
type="class"
)
print(zip.rf)
?zip.rf
zip.rf.predict
predict.randomForest(xtest)
xtest <- zip.test[,2:257]
predict.randomForest(xtest)
predict(xtest)
xtest <- data.frame(zip.test[,2:257])
predict(xtest)
predict(zip.rf, newdata=xtest)
xtest <- data.frame(zip.test[,2:257])
predict(zip.rf, newdata=xtest)
str(zip.rf)
zip.rf$votes
zip.rf$votes[1,]
zip.test[1,]
dim(zip.test)
i <- sample(nrow(zip.test))
i
i <- sample(nrow(zip.test), 1)
sample(nrow(zip.test), 1)
sample(nrow(zip.test), 1)
sample(nrow(zip.test), 1)
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$votes[i,]
dim(zip.rf$votes)
i <- sample(nrow(zip.train), 1); zip.train[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.train), 1); zip.train[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.train), 1); zip.train[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.train), 1); zip.train[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.train), 1); zip.train[i,1]; zip.rf$votes[i,]
i <- sample(nrow(zip.train), 1); zip.train[i,1]; zip.rf$votes[i,]
str(zip.rf)
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$test$votes[i,]
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$test$votes[i,]
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$test$votes[i,]
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$test$votes[i,]
i <- sample(nrow(zip.test), 1); zip.test[i,1]; zip.rf$test$votes[i,]
meshsize <- 0.05
arr <- rep(0, 1/meshsize)
arr
zip.rf$test$votes[i,]
zip.rf$test$votes[i,][2]
as.numeric(zip.rf$test$votes[i,][2])
as.numeric(zip.rf$test$votes[i,])
0.968/meshsize
floor(0.968/meshsize)
ceiling(0.968/meshsize)
str(zip.rf)
zip.rf$test$predicted[i]
i=1
j=1
prob <- as.numeric(zip.rf$test$votes[i,j])
idx <- ceiling(prob/meshsize)
idx
zip.rf$test$predicted[i] == idx
meshsize <- 0.05
len <- 1/meshsize
arr.num <- rep(0, len) # counts correct predictions
arr.den <- rep(0, len) # counts all predictions
for(i in 1:nrow(zip.test)){
for(j in 1:len){
prob <- as.numeric(zip.rf$test$votes[i,j])
idx <- ceiling(prob/meshsize)
arr.den[idx] <- arr.den[idx] + 1
if(zip.rf$test$predicted[i] == idx) arr.num[idx] <- arr.num[idx] + 1
}
}
zip.rf$test$votes
dim(zip.rf$test$votes)
len
arr.num <- rep(0, len) # counts correct predictions
arr.den <- rep(0, len) # counts all predictions
for(i in 1:nrow(zip.test)){
for(j in 1:10){
prob <- as.numeric(zip.rf$test$votes[i,j])
idx <- ceiling(prob/meshsize)
arr.den[idx] <- arr.den[idx] + 1
if(zip.rf$test$predicted[i] == idx) arr.num[idx] <- arr.num[idx] + 1
}
}
arr.num
arr.den
calib <- arr.num/arr.den
plot(calib)
calib
arr.num <- rep(0, len) # counts correct predictions
arr.den <- rep(0, len) # counts all predictions
for(i in 1:nrow(zip.test)){
for(j in 1:10){
prob <- as.numeric(zip.rf$test$votes[i,j])
idx <- ceiling(prob/meshsize)
arr.den[idx] <- arr.den[idx] + 1
if(zip.rf$test$predicted[i] == j) arr.num[idx] <- arr.num[idx] + 1
}
}
calib <- arr.num/arr.den
plot(calib)
arr.num
prob <- as.numeric(zip.rf$test$votes[i,j])
prob
idx <- ceiling(prob/meshsize)
zip.rf$test$predicted[i]
j
arr.num <- rep(0, len) # counts correct predictions
arr.den <- rep(0, len) # counts all predictions
for(i in 1:nrow(zip.test)){
for(j in 1:10){
prob <- as.numeric(zip.rf$test$votes[i,j])
idx <- ceiling(prob/meshsize)
arr.den[idx] <- arr.den[idx] + 1
if(zip.rf$test$predicted[i] == j-1) arr.num[idx] <- arr.num[idx] + 1
}
}
calib <- arr.num/arr.den
plot(calib)
xax <- 1:len / meshsize
xax
xax <- (1:len) / len
plot(calib ~ xax, type='b', col='blue', frame.plot=0)
plot(calib ~ xax,
xlab="Probability estimate",
ylab="Observed probability",
type='b', col='blue', frame.plot=0)
setwd("~/Dropbox/Projects/201701-oneshotzip")
library(ElemStatLearn)
summary(zip.train)
zip.sym <- zip.train[,1]
zip.sym
zip.vec <- zip.train[,2:257]
dat <- read.table("zip_fiedler.txt")
library(Rtsne)
nclass <- 10
a <- 0.5
b <- (1-a)/nclass
P <- matrix(
nrow=nclass, ncol=nclass,
byrow=TRUE,
data = rep(b, nclass^2)
)
for(i in 1:(nclass-1)){ P[i,i+1]=a }; P[nclass,1]=a
q0 <- rep(1/nclass,nclass)
generate <- function(T, P){
out <- c(1)
for(t in 2:T){
x <- sample(1:nclass,1, prob=P[out[t-1],])
out <- c(out, x)
}
# return:
out
}
state <- generate(50, P)
plot(state, col='blue', type='b', pch=19)
baum.welch <- function(dat, P,
variance=1.0,
update.covariance=TRUE,
niters=30,
verbose=TRUE){
# rows of dat are the observed vector sequence
# P is the known transition matrix
# 'emission':
y <- dat
T <- nrow(dat) # nr time-steps
k <- ncol(dat) # dimension
# nr classes:
nclass <- nrow(P)
# initial q estimate:
q <- rep(1/nclass,nclass)
# initial mu estimate:
mu0 <- lapply(1:nclass, function(i) rnorm(k))
# initial sigma estimate:
sigma0 <- lapply(1:nclass, function(i) diag(rep(variance, k)))
# initialise alpha, beta vectors:
alpha = matrix(
nrow = nclass,
ncol = T
)
beta = matrix(
nrow = nclass,
ncol = T
)
# intialise mu, sigma:
mu <- mu0
sigma <- sigma0
for(iter in 1:niters){
# E-step - forward-backward
# prepare:
inv_sig <- lapply(sigma, solve)
ldet_sig <- lapply(sigma, function(mat) log(det(mat))/2)
const <- k * log(2*pi)/2
F <- function(v){
# for vector v, returns density of v under each Gaussian,
# one for each centroid and covariance
f <- function(i){
lg <- - t(v - mu[[i]]) %*% inv_sig[[i]] %*% (v - mu[[i]])/2 - ldet_sig[[i]] - const
# return:
exp(lg)
}
# return:
sapply(1:nclass, f)
}
# alpha pass:
alpha[,1] <- q * F(y[1,])
for(j in 2:T){
alpha[,j] <- ( t(alpha[,j-1]) %*% P ) * F(y[j,])
alpha[,j] <- alpha[,j] / sum(alpha[,j])
}
# beta pass
beta[,T] = rep(1,nclass)
for(j in ((T-1):1)){
beta[,j] <- t(beta[,j+1] * F(y[j+1,])) %*% t(P)
beta[,j] <- beta[,j] / sum(beta[,j])
}
# gamma pass
gamma <- alpha * beta
zed <- colSums(gamma)
for(i in 1:nclass) gamma[i,] <- gamma[i,] / zed
# M-step - re-estimate q, mu, sigma
q <- gamma[,1]
mu <- as.list(data.frame( t(gamma %*% y) ))
zed <- rowSums(gamma)
for(j in 1:nclass) mu[[j]] <- mu[[j]] / zed[j]
# note in passing that zed estimates the class sizes in the training data:
if(verbose) cat(iter,":", sapply(zed, round), "\n")
# covariance:
if(update.covariance){
sigma <- list()
for(i in 1:nclass){
tmp <- y - matrix(rep(mu[[i]], T), nrow=T, byrow=TRUE)
sigma[[i]] <- t(tmp) %*% (gamma[i,] * tmp) / zed[i]
}
}
}
# return:
list(gamma=gamma,
path = path <- sapply(1:T, function(t){ order(gamma[,t])[nclass] }),
mu = mu,
sigma = sigma)
}
zip <- read.table("zip_fiedler.txt")
zip.vec <- zip[,1:9]
zip.sym <- zip[,10]
T <- nrow(zip.vec)
k <- ncol(zip.vec)
state <- generate(T,P)
dat <- matrix(0,nrow=T, ncol=k)
idx <- lapply(1:10, function(i) which(zip.sym==i%%10))
for(i in 1:T){
dat[i,] <- as.matrix(zip.vec[sample(idx[[state[i]]], 1),])
}
bw <- baum.welch(dat, P, variance=1.0, P, niters=100, update.covariance=TRUE)
table(bw$path, state)
setwd("~/Dropbox/Projects/201701-oneshotzip")
source("functions.R")
mosaicplot(t(bw$gamma[,1:50]))
confidence <- sapply(1:T, function(t) max(bw$gamma[,t]))
plot(-log(confidence), type='l', col='blue')
hist(confidence, col='grey', breaks=20)
hist(confidence, col='grey', breaks=20, log='y')
hist(log(confidence,2), col='grey', breaks=20)
cond <- (confidence > 0.99)
table(bw$path[cond], state[cond])
table(bw$path, state)
h <- hist(confidence, col='grey', breaks=20)
str(h)
h$counts
sum(h$counts) - max(h$counts)
cbind(h$mids, h$counts)
